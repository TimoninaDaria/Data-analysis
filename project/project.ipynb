{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Итоговый проект"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T13:02:40.666204Z",
     "start_time": "2020-05-24T13:02:18.463933Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from os import listdir\n",
    "import codecs\n",
    "import pickle                                                                   \n",
    "from bs4 import BeautifulSoup as BS\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from boilerpipe.extract import Extractor\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.ensemble import IsolationForest\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T13:02:40.869635Z",
     "start_time": "2020-05-24T13:02:40.670052Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_groups.csv',dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T13:27:27.866593Z",
     "start_time": "2020-05-24T13:27:27.845753Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "test_data= pd.read_csv('test_groups.csv',dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T13:48:34.201028Z",
     "start_time": "2020-05-24T13:27:49.267712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: NumWordsRulesExtractor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                     | 43/28026 [00:06<1:25:20,  5.46it/s]"
     ]
    }
   ],
   "source": [
    "#это парсинг теста\n",
    "import pandas as pd                                                             \n",
    "import numpy as np                                                              \n",
    "from tqdm import tqdm                                                           \n",
    "from os import listdir                                                          \n",
    "import codecs                                                                   \n",
    "import pickle                                                                   \n",
    "from bs4 import BeautifulSoup as BS                                             \n",
    "from boilerpipe.extract import Extractor                                        \n",
    "from sys import argv                                                            \n",
    "                                                                                \n",
    "parser_type = 'NumWordsRulesExtractor'\n",
    "def save_obj(obj, name ):                                                       \n",
    "    with open(name + '.pkl', 'wb') as f:                                        \n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)                            \n",
    "                                                                                \n",
    "def load_obj(name ):                                                            \n",
    "    with open(name + '.pkl', 'rb') as f:                                        \n",
    "        return pickle.load(f)                                                   \n",
    "                                                                                \n",
    "path = 'content/'                                                               \n",
    "texts = {}                                                                      \n",
    "print('Start: ' + parser_type)                                                  \n",
    "test_data = pd.read_csv('test_groups.csv',dtype=np.int16)                      \n",
    "#for filename in ['6770.dat']:                                                  \n",
    "for filename in tqdm(listdir(path)):                                            \n",
    "    doc_id = int(filename.strip('.dat'))                                        \n",
    "    if doc_id not in test_data.doc_id.values:                                  \n",
    "        continue                                                                \n",
    "    try:                                                                        \n",
    "        with codecs.open(path + filename, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            url = f.readline().strip()                                          \n",
    "            html = f.read()                                                     \n",
    "            extractor = Extractor(extractor=parser_type, html=html)             \n",
    "            s = extractor.getText()                                             \n",
    "            s=s.replace('\\n',\" \")                                               \n",
    "            s=s.replace('\\t',\" \")                                               \n",
    "            s=s.replace('\\r',\" \")                                               \n",
    "            texts[doc_id] = s                                                   \n",
    "    except UnicodeDecodeError: \n",
    "        print('error {}'.format(filename))                                      \n",
    "        with codecs.open(path + filename, 'r', 'utf-8') as f:                   \n",
    "            url = f.readline().strip()                                          \n",
    "            html = f.read()                                                     \n",
    "        bs = BS(html, 'html.parser')#ищем след страницу                         \n",
    "        for s in bs.select('script'):                                           \n",
    "            s.extract()                                                         \n",
    "        s = bs.get_text()                                                       \n",
    "        s=s.replace('\\n',\"\")                                                    \n",
    "        s=s.replace('\\t',\"\")                                                    \n",
    "        s=s.replace('\\r',\"\")                                                    \n",
    "        texts[doc_id] = s                                                       \n",
    "test_data['text'] = test_data.apply(lambda row: texts[row.doc_id], axis = 1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T13:02:40.985488Z",
     "start_time": "2020-05-24T13:02:40.879097Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):                                                       \n",
    "    with open(name + '.pkl', 'wb') as f:                                        \n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)                            \n",
    "                                                                                \n",
    "def load_obj(name ):                                                            \n",
    "    with open(name + '.pkl', 'rb') as f:                                        \n",
    "        return pickle.load(f)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T13:02:41.085019Z",
     "start_time": "2020-05-24T13:02:40.993380Z"
    }
   },
   "outputs": [],
   "source": [
    "#START HEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T13:02:41.163122Z",
     "start_time": "2020-05-24T13:02:41.088553Z"
    }
   },
   "outputs": [],
   "source": [
    "name = 'NumWordsRulesExtractor'\n",
    "name = 'train_data'+name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T13:03:04.852015Z",
     "start_time": "2020-05-24T13:02:41.165606Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = load_obj(name)#Загружаем готовый распарсенный текст уже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T13:03:27.478974Z",
     "start_time": "2020-05-24T13:03:27.455656Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T13:49:18.603829Z",
     "start_time": "2020-05-24T13:49:18.284046Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28026\n"
     ]
    }
   ],
   "source": [
    "doc_to_title = {}\n",
    "with open('docs_titles.tsv', encoding = 'UTF-8') as f:\n",
    "    for num_line, line in enumerate(f):\n",
    "        if num_line == 0:\n",
    "            continue\n",
    "        data = line.strip().split('\\t', 1)\n",
    "        doc_id = int(data[0])\n",
    "        if len(data) == 1:\n",
    "            title = ''\n",
    "        else:\n",
    "            title = data[1]\n",
    "        doc_to_title[doc_id] = title\n",
    "print (len(doc_to_title))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T13:49:28.015210Z",
     "start_time": "2020-05-24T13:49:27.986110Z"
    }
   },
   "outputs": [],
   "source": [
    "doc_titles = []\n",
    "for id in train_data.doc_id.values:\n",
    "    doc_titles.append(doc_to_title[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T13:49:28.604052Z",
     "start_time": "2020-05-24T13:49:28.310433Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data['title'] = doc_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T13:49:20.380048Z",
     "start_time": "2020-05-24T13:49:20.334685Z"
    }
   },
   "outputs": [],
   "source": [
    "test_doc_titles = []\n",
    "for id in test_data.doc_id.values:\n",
    "    test_doc_titles.append(doc_to_title[id])\n",
    "test_data['title'] = test_doc_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T13:49:30.843134Z",
     "start_time": "2020-05-24T13:49:30.837677Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_splits(data,n=3):\n",
    "    bound =[]\n",
    "    max_group = data.group_id.max()\n",
    "    bound.extend([i*int(max_group/n)+1 for i in range(1,n)])\n",
    "    bound.append(max_group+1)\n",
    "    prev_id = 1\n",
    "    for group_id in bound:\n",
    "        yield (data[~((prev_id <= data.group_id) & (data.group_id < group_id))].pair_id.values-1,\n",
    "            data[(prev_id <= data.group_id) & (data.group_id < group_id)].pair_id.values-1)\n",
    "        prev_id = group_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T13:56:46.512357Z",
     "start_time": "2020-05-24T13:56:46.494087Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range = (1,3))#max_features = 70)\n",
    "#texts_vectorized = vectorizer.fit_transform(train_data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T13:56:46.955516Z",
     "start_time": "2020-05-24T13:56:46.950475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([130, 130, 130, ..., 309, 309, 309], dtype=int16)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.group_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T13:49:35.530456Z",
     "start_time": "2020-05-24T13:49:35.527118Z"
    }
   },
   "outputs": [],
   "source": [
    "groups_tmp = np.concatenate((train_data.group_id.values,  test_data.group_id.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T13:57:43.266515Z",
     "start_time": "2020-05-24T13:57:43.259379Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  4],\n",
       "       [  5],\n",
       "       [  6],\n",
       "       [  7],\n",
       "       [  8],\n",
       "       [  9],\n",
       "       [ 10],\n",
       "       [ 11],\n",
       "       [ 12],\n",
       "       [ 13],\n",
       "       [ 14],\n",
       "       [ 15],\n",
       "       [ 16],\n",
       "       [ 17],\n",
       "       [ 18],\n",
       "       [ 19],\n",
       "       [ 20],\n",
       "       [ 21],\n",
       "       [ 22],\n",
       "       [ 23],\n",
       "       [ 24],\n",
       "       [ 25],\n",
       "       [ 26],\n",
       "       [ 27],\n",
       "       [ 28],\n",
       "       [ 29],\n",
       "       [ 30],\n",
       "       [ 31],\n",
       "       [ 32],\n",
       "       [ 33],\n",
       "       [ 34],\n",
       "       [ 35],\n",
       "       [ 36],\n",
       "       [ 37],\n",
       "       [ 38],\n",
       "       [ 39],\n",
       "       [ 40],\n",
       "       [ 41],\n",
       "       [ 42],\n",
       "       [ 43],\n",
       "       [ 44],\n",
       "       [ 45],\n",
       "       [ 46],\n",
       "       [ 47],\n",
       "       [ 48],\n",
       "       [ 49],\n",
       "       [ 50],\n",
       "       [ 51],\n",
       "       [ 52],\n",
       "       [ 53],\n",
       "       [ 54],\n",
       "       [ 55],\n",
       "       [ 56],\n",
       "       [ 57],\n",
       "       [ 58],\n",
       "       [ 59],\n",
       "       [ 60],\n",
       "       [ 61],\n",
       "       [ 62],\n",
       "       [ 63],\n",
       "       [ 64],\n",
       "       [ 65],\n",
       "       [ 66],\n",
       "       [ 67],\n",
       "       [ 68],\n",
       "       [ 69],\n",
       "       [ 70],\n",
       "       [ 71],\n",
       "       [ 72],\n",
       "       [ 73],\n",
       "       [ 74],\n",
       "       [ 75],\n",
       "       [ 76],\n",
       "       [ 77],\n",
       "       [ 78],\n",
       "       [ 79],\n",
       "       [ 80],\n",
       "       [ 81],\n",
       "       [ 82],\n",
       "       [ 83],\n",
       "       [ 84],\n",
       "       [ 85],\n",
       "       [ 86],\n",
       "       [ 87],\n",
       "       [ 88],\n",
       "       [ 89],\n",
       "       [ 90],\n",
       "       [ 91],\n",
       "       [ 92],\n",
       "       [ 93],\n",
       "       [ 94],\n",
       "       [ 95],\n",
       "       [ 96],\n",
       "       [ 97],\n",
       "       [ 98],\n",
       "       [ 99],\n",
       "       [100],\n",
       "       [101],\n",
       "       [102],\n",
       "       [103],\n",
       "       [104],\n",
       "       [105],\n",
       "       [106],\n",
       "       [107],\n",
       "       [108],\n",
       "       [109],\n",
       "       [110],\n",
       "       [111],\n",
       "       [112],\n",
       "       [113],\n",
       "       [114],\n",
       "       [115],\n",
       "       [116],\n",
       "       [117],\n",
       "       [118],\n",
       "       [119],\n",
       "       [120],\n",
       "       [121],\n",
       "       [122],\n",
       "       [123],\n",
       "       [124],\n",
       "       [125],\n",
       "       [126],\n",
       "       [127],\n",
       "       [128],\n",
       "       [129],\n",
       "       [130],\n",
       "       [131],\n",
       "       [132],\n",
       "       [133],\n",
       "       [134],\n",
       "       [135],\n",
       "       [136],\n",
       "       [137],\n",
       "       [138],\n",
       "       [139],\n",
       "       [140],\n",
       "       [141],\n",
       "       [142],\n",
       "       [143],\n",
       "       [144],\n",
       "       [145],\n",
       "       [146],\n",
       "       [147],\n",
       "       [148],\n",
       "       [149],\n",
       "       [150],\n",
       "       [151],\n",
       "       [152],\n",
       "       [153],\n",
       "       [154],\n",
       "       [155],\n",
       "       [156],\n",
       "       [157],\n",
       "       [158],\n",
       "       [159],\n",
       "       [160],\n",
       "       [161],\n",
       "       [162],\n",
       "       [163],\n",
       "       [164],\n",
       "       [165],\n",
       "       [166],\n",
       "       [167],\n",
       "       [168],\n",
       "       [169],\n",
       "       [170],\n",
       "       [171],\n",
       "       [172],\n",
       "       [173],\n",
       "       [174],\n",
       "       [175],\n",
       "       [176],\n",
       "       [177],\n",
       "       [178],\n",
       "       [179],\n",
       "       [180],\n",
       "       [181],\n",
       "       [182],\n",
       "       [183],\n",
       "       [184],\n",
       "       [185],\n",
       "       [186],\n",
       "       [187],\n",
       "       [188],\n",
       "       [189],\n",
       "       [190],\n",
       "       [191],\n",
       "       [192],\n",
       "       [193],\n",
       "       [194],\n",
       "       [195],\n",
       "       [196],\n",
       "       [197],\n",
       "       [198],\n",
       "       [199],\n",
       "       [200],\n",
       "       [201],\n",
       "       [202],\n",
       "       [203],\n",
       "       [204],\n",
       "       [205],\n",
       "       [206],\n",
       "       [207],\n",
       "       [208],\n",
       "       [209],\n",
       "       [210],\n",
       "       [211],\n",
       "       [212],\n",
       "       [213],\n",
       "       [214],\n",
       "       [215],\n",
       "       [216],\n",
       "       [217],\n",
       "       [218],\n",
       "       [219],\n",
       "       [220],\n",
       "       [221],\n",
       "       [222],\n",
       "       [223],\n",
       "       [224],\n",
       "       [225],\n",
       "       [226],\n",
       "       [227],\n",
       "       [228],\n",
       "       [229],\n",
       "       [230],\n",
       "       [231],\n",
       "       [232],\n",
       "       [233],\n",
       "       [234],\n",
       "       [235],\n",
       "       [236],\n",
       "       [237],\n",
       "       [238],\n",
       "       [239],\n",
       "       [240],\n",
       "       [241],\n",
       "       [242],\n",
       "       [243],\n",
       "       [244],\n",
       "       [245],\n",
       "       [246],\n",
       "       [247],\n",
       "       [248],\n",
       "       [249],\n",
       "       [250],\n",
       "       [251],\n",
       "       [252],\n",
       "       [253],\n",
       "       [254],\n",
       "       [255],\n",
       "       [256],\n",
       "       [257],\n",
       "       [258],\n",
       "       [259],\n",
       "       [260],\n",
       "       [261],\n",
       "       [262],\n",
       "       [263],\n",
       "       [264],\n",
       "       [265],\n",
       "       [266],\n",
       "       [267],\n",
       "       [268],\n",
       "       [269],\n",
       "       [270],\n",
       "       [271],\n",
       "       [272],\n",
       "       [273],\n",
       "       [274],\n",
       "       [275],\n",
       "       [276],\n",
       "       [277],\n",
       "       [278],\n",
       "       [279],\n",
       "       [280],\n",
       "       [281],\n",
       "       [282],\n",
       "       [283],\n",
       "       [284],\n",
       "       [285],\n",
       "       [286],\n",
       "       [287],\n",
       "       [288],\n",
       "       [289],\n",
       "       [290],\n",
       "       [291],\n",
       "       [292],\n",
       "       [293],\n",
       "       [294],\n",
       "       [295],\n",
       "       [296],\n",
       "       [297],\n",
       "       [298],\n",
       "       [299],\n",
       "       [300],\n",
       "       [301],\n",
       "       [302],\n",
       "       [303],\n",
       "       [304],\n",
       "       [305],\n",
       "       [306],\n",
       "       [307],\n",
       "       [308],\n",
       "       [309]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr = np.array(list(range(1,310))).reshape(-1,1)\n",
    "gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T13:57:46.718579Z",
     "start_time": "2020-05-24T13:57:46.706553Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11690x309 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 11690 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "i = OneHotEncoder()\n",
    "i.fit(gr)\n",
    "groups_one_hot = i.transform(train_data.group_id.values.reshape(-1,1))\n",
    "groups_one_hot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T13:57:49.295903Z",
     "start_time": "2020-05-24T13:57:49.291416Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11690x309 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 11690 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T13:49:47.852596Z",
     "start_time": "2020-05-24T13:49:47.849955Z"
    }
   },
   "outputs": [],
   "source": [
    "#texts_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T13:57:52.262685Z",
     "start_time": "2020-05-24T13:57:52.258008Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "from scipy.sparse import vstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T13:57:52.751250Z",
     "start_time": "2020-05-24T13:57:52.747875Z"
    }
   },
   "outputs": [],
   "source": [
    "#features = hstack( [texts_vectorized,groups_one_hot] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T13:21:29.742088Z",
     "start_time": "2020-05-24T13:21:29.734857Z"
    }
   },
   "outputs": [],
   "source": [
    "target = train_data.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T13:21:30.189437Z",
     "start_time": "2020-05-24T13:21:30.184603Z"
    }
   },
   "outputs": [],
   "source": [
    "#doc_id = train_data.doc_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T13:58:01.618180Z",
     "start_time": "2020-05-24T13:58:01.615226Z"
    }
   },
   "outputs": [],
   "source": [
    "groups = train_data.group_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T13:58:02.080699Z",
     "start_time": "2020-05-24T13:58:02.076293Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   1,   1, ..., 129, 129, 129], dtype=int16)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T13:59:08.842702Z",
     "start_time": "2020-05-24T13:59:08.840292Z"
    }
   },
   "outputs": [],
   "source": [
    "data = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T14:04:17.738140Z",
     "start_time": "2020-05-24T13:59:09.007477Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d42995ff66c04be6b1dd4ac481509752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=129.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "number = 1\n",
    "for group in tqdm(set(groups)):\n",
    "    number +=1\n",
    "    elements_in_same_group = data.group_id == group\n",
    "\n",
    "    vectorizer.fit(data.title[elements_in_same_group] + data.text[elements_in_same_group])\n",
    "    texts_vectorized_titles = vectorizer.transform(data.title[elements_in_same_group])\n",
    "    texts_vectorized_titles = scaler.fit_transform(texts_vectorized_titles)\n",
    "    \n",
    "    texts_vectorized_texts = vectorizer.transform(data.text[elements_in_same_group])\n",
    "    texts_vectorized_texts = scaler.fit_transform(texts_vectorized_texts)\n",
    "\n",
    "    dist_matr = pairwise_distances(texts_vectorized_titles, texts_vectorized_titles, metric = 'cosine')\n",
    "    dist_matr2 = pairwise_distances(texts_vectorized_texts, texts_vectorized_texts, metric = 'cosine')\n",
    "    dist_matr3 = pairwise_distances(texts_vectorized_texts, texts_vectorized_titles, metric = 'cosine')\n",
    "\n",
    "    #clustering = DBSCAN(eps = 1.3, min_samples=5).fit(dist_matr)\n",
    "    #clf = IsolationForest(random_state=0).fit_predict(dist_matr)\n",
    "    \n",
    "    dist_matr_sorted = np.sort(dist_matr,axis=1)[:,0:min(50,dist_matr.shape[1])]\n",
    "    dist_matr_sorted2 = np.sort(dist_matr2,axis=1)[:,0:min(50,dist_matr2.shape[1])]\n",
    "    dist_matr_sorted3 = np.sort(dist_matr3,axis=1)[:,0:min(50,dist_matr3.shape[1])]\n",
    "    \n",
    "    if dist_matr_sorted.shape[1] < 50:\n",
    "        dist_matr_sorted = np.hstack((dist_matr_sorted, np.tile(dist_matr_sorted[:,-1:], (1, 50-dist_matr_sorted.shape[1]))))\n",
    "        dist_matr_sorted2 = np.hstack((dist_matr_sorted2, np.tile(dist_matr_sorted2[:,-1:], (1, 50-dist_matr_sorted2.shape[1]))))\n",
    "        dist_matr_sorted3 = np.hstack((dist_matr_sorted3, np.tile(dist_matr_sorted3[:,-1:], (1, 50-dist_matr_sorted3.shape[1]))))\n",
    "\n",
    "        \n",
    "    mean_dist = dist_matr.mean(axis = 1)\n",
    "    dist_matr_sorted = np.hstack((dist_matr_sorted, mean_dist.reshape(-1,1)))\n",
    "    dist_matr_sorted = np.hstack((dist_matr_sorted, dist_matr_sorted2))\n",
    "    dist_matr_sorted = np.hstack((dist_matr_sorted, dist_matr_sorted3))\n",
    "   # dist_matr_sorted = np.hstack((dist_matr_sorted, clustering.labels_.reshape(-1,1)))\n",
    "#   dist_matr_sorted = hstack((dist_matr_sorted, texts_vectorized))\n",
    "    \n",
    "    if number == 2 :\n",
    "        features_by_dist =  dist_matr_sorted\n",
    "    else:\n",
    "        features_by_dist = vstack((features_by_dist, dist_matr_sorted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T14:04:39.495771Z",
     "start_time": "2020-05-24T14:04:39.478846Z"
    }
   },
   "outputs": [],
   "source": [
    "features_by_dist = hstack([features_by_dist, groups_one_hot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T14:04:40.236959Z",
     "start_time": "2020-05-24T14:04:39.929563Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11690, 460)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_by_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T13:56:29.469329Z",
     "start_time": "2020-05-24T13:56:24.322398Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-e8c0dad212ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_by_dist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0msave_obj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[1;32m--> 383\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1018\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    907\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#SAVE model\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "model = RandomForestClassifier(n_jobs=6,n_estimators=200)\n",
    "model.fit(features_by_dist.tocsr(), target)\n",
    "save_obj(model, 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T13:56:38.304216Z",
     "start_time": "2020-05-24T13:56:29.475150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.coo.coo_matrix'>\n",
      "[0.7142199723884032]\n",
      "<class 'scipy.sparse.coo.coo_matrix'>\n",
      "[0.7142199723884032, 0.6963481740870434]\n",
      "<class 'scipy.sparse.coo.coo_matrix'>\n",
      "[0.7142199723884032, 0.6963481740870434, 0.728912945421741]\n",
      "0.7131603639657292\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "max_score = 0\n",
    "scores = []\n",
    "for train, test in get_splits(train_data,n=3):\n",
    "            print(type(features_by_dist))\n",
    "            model = RandomForestClassifier(n_jobs=6,n_estimators=200)\n",
    "            model.fit(features_by_dist.tocsr()[train], target[train])\n",
    "            pred = (model.predict(features_by_dist.tocsr()[test]))               \n",
    "            scores.append(f1_score(pred,target[test]))\n",
    "            print(scores)\n",
    "print(sum(scores)/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T14:04:46.400215Z",
     "start_time": "2020-05-24T14:04:46.045967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.coo.coo_matrix'>\n"
     ]
    }
   ],
   "source": [
    "#SUBMIT\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "print(type(features_by_dist))\n",
    "model = load_obj('model') \n",
    "pred = (model.predict(features_by_dist.tocsr()))               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T14:04:54.432530Z",
     "start_time": "2020-05-24T14:04:54.428666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16627,)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T14:05:15.364714Z",
     "start_time": "2020-05-24T14:05:15.360987Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data['target'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T14:08:13.674845Z",
     "start_time": "2020-05-24T14:08:13.624151Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data.to_csv('sub',index=False,columns=['pair_id','target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nav_menu": {},
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "402px",
    "width": "253px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
